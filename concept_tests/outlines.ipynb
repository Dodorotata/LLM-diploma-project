{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "content\n",
    "conclusions\n",
    "---\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from outlines import models, generate\n",
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:   no\n",
      "ggml_cuda_init: CUDA_USE_TENSOR_CORES: yes\n",
      "ggml_cuda_init: found 1 CUDA devices:\n",
      "  Device 0: NVIDIA GeForce RTX 4070 Ti, compute capability 8.9, VMM: yes\n"
     ]
    }
   ],
   "source": [
    "llm = Llama(\"/home/dorota/models/mistral-7b-instruct-v0.2.Q6_K.gguf\", n_gpu_layers=10, n_ctx=0, verbose=False)\n",
    "model = models.LlamaCpp(llm) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mistral = models.transformers(\"mistralai/Mistral-7B-v0.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "????????? output ok if age: int is removed or if code run with mistralai/Mistral-7B-v0.1???????????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "class User(BaseModel):\n",
    "    first_name: str\n",
    "    last_name: str\n",
    "    # age: int\n",
    "\n",
    "generator = generate.json(model, User)\n",
    "\n",
    "result = generator(\n",
    "    \"\"\"Based on user information create a user profile with the fields first_name, last_name.\n",
    "    User information is: Jane Doe 10\"\"\"\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from outlines import models, generate\n",
    "\n",
    "\n",
    "class User(BaseModel):\n",
    "    name: str\n",
    "    last_name: str\n",
    "    id: int\n",
    "\n",
    "generator = generate.json(model_mistral, User)\n",
    "result = generator(\n",
    "    \"Create a user profile with the fields name, last_name and id.  User information is: Jane Doe 123\"\n",
    ")\n",
    "print(dict(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below can only be run with model_mistral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with Pydantic and own text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader \n",
    "  \n",
    "reader = PdfReader('/home/dorota/LLM-diploma-project/00_concept_tests/data/40001_2023_Article_1364.pdf') \n",
    "num_pages = len(reader.pages)\n",
    "TEXT = \"\"\n",
    "for page_num in range(1): #change to range(num_pages) for whole document\n",
    "    page = reader.pages[page_num]  \n",
    "    TEXT += page.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class Metadata(BaseModel):\n",
    "    title: str = Field(..., description=\"extract title from article\")\n",
    "    authors: str = Field(..., description=\"extract authors from article\")\n",
    "    pub_year: int = Field(..., description=\"extract publication year\")\n",
    "    key_words: str = Field(..., description=\"generate 5 new key words based on content in Abstract\")\n",
    "    summary: str = Field(..., description=\"generate summary in 3 sentences\")\n",
    "    research_area: str = Field(..., description=\"generate 1 main research area described in article\")\n",
    "    quality: str = Field(..., description=\"select one value from provided examples to define quality of article\", examples=['GOOD', 'BAD', 'EXCELLENT', 'CAN NOT SET QUALITY'])\n",
    "    quality_reason: str = Field(..., description=\"describe reason for chosen quality_score in 1 sentece\")\n",
    "\n",
    "generator = generate.json(model_mistral, Metadata)\n",
    "prompt = \"\"\"\n",
    "                Article is delimited by (start) and (stop):\n",
    "                (start)\n",
    "                {{TEXT}}\n",
    "                (stop)\n",
    "                Generate output based on the Article corresponding to the Metadata class\n",
    "                \"\"\"\n",
    "                \n",
    "result = generator(prompt)\n",
    "\n",
    "dict(result)\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "# NOTE output has correc headings but content is not based on article provided\n",
    "# {'title': 'Document title',\n",
    " #'authors': 'John J. Nixon, John W. Inplace,David R. None, and Stephen M. S. oninc',\n",
    " #'pub_year': 2016,\n",
    " #'key_words': 'text',\n",
    " #'summary': 'This is a rjohnsntroducttory document how to use and develop OpenCadflow environment',\n",
    " #'research_area': 'science.agriculture',\n",
    " #'quality': 'submitted_document',\n",
    " #'quality_reason': 'Copy from other publications without changes'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with prompt where field name and description are manually inserted into the prompt from Pydantic class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import outlines\n",
    "import outlines.generate\n",
    "import outlines.generate.json\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class Metadata(BaseModel):\n",
    "    title: str = Field(..., description=\"extract title from article\")\n",
    "    authors: str = Field(..., description=\"extract authors from article\")\n",
    "    pub_year: int = Field(..., description=\"extract publication year\")\n",
    "    key_words: str = Field(..., description=\"generate 5 new key words based on content in Abstract\")\n",
    "    summary: str = Field(..., description=\"generate summary in 3 sentences\")\n",
    "    research_area: str = Field(..., description=\"generate 1 main research area described in article\")\n",
    "    quality: str = Field(..., description=\"select one value from provided examples to define quality of article\", examples=['GOOD', 'BAD', 'EXCELLENT', 'CAN NOT SET QUALITY'])\n",
    "    quality_reason: str = Field(..., description=\"describe reason for chosen quality_score in 1 sentece\")\n",
    "\n",
    "@outlines.prompt\n",
    "def get_metadata(text):\n",
    "    \"\"\"Article is delimited by (start) and (stop):\n",
    "    (start)\n",
    "    {{text}}\n",
    "    (stop)\n",
    "    Based on the article content, generate fields listed below according to their descriptions. \n",
    "    title: description=\"extract title from article\"\n",
    "    authors: description=\"extract authors from article\"\n",
    "    pub_year: description=\"extract publication year\"\n",
    "    key_words: description=\"generate 5 new key words based on content in Abstract\"\n",
    "    summary: description=\"generate summary in 3 sentences\"\n",
    "    research_area: description=\"generate 1 main research area described in article\"\n",
    "    quality: description=\"select one value from ['GOOD', 'BAD', 'EXCELLENT', 'CAN NOT SET QUALITY'] to define quality of article\"\n",
    "    quality_reason: description=\"describe reason for chosen quality_score in 1 sentece\"\n",
    "    \"\"\"\n",
    "prompt = get_metadata(TEXT)\n",
    "generator = outlines.generate.json(model_mistral, Metadata)\n",
    "result = generator(prompt)\n",
    "\n",
    "result.model_dump()\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------\n",
    "# NOTE good quality output\n",
    "#{'title': 'Visualization of breast cancer-related protein synthesis from  the perspective   of bibliometric analysis ',\n",
    "# 'authors': 'Jiawei Xu, Chengdong Yu, Xiaoqiang Zeng, Weifeng Tang, Siyi Xu, Lei Tang, Yanxiao Huang, Zhengkui Sun , Tenghua Yu*',\n",
    "# 'pub_year': 2023,\n",
    "# 'key_words': 'breast cancer, cancer, protein, expression, translation',\n",
    "# 'summary': 'The Our analysis of the relationship between protein expression in breast cancer and the  development and  treatment of tumors.',\n",
    "# 'research_area': 'oncology, hematology',\n",
    "# 'quality': 'EXCELLENT',\n",
    "# 'quality_reason': 'Presentation of content is good. '}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with prompt with Pydantc class schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import outlines\n",
    "import outlines.generate\n",
    "import outlines.generate.json\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class Metadata(BaseModel):\n",
    "    title: str = Field(..., description=\"extract title from article\")\n",
    "    authors: str = Field(..., description=\"extract authors from article\")\n",
    "    pub_year: int = Field(..., description=\"extract publication year\")\n",
    "    key_words: str = Field(..., description=\"generate 5 new key words based on content in Abstract\")\n",
    "    summary: str = Field(..., description=\"generate summary in 3 sentences\")\n",
    "    research_area: str = Field(..., description=\"generate 1 main research area described in article\")\n",
    "    quality: str = Field(..., description=\"select one value from examples to define quality of article\", examples=['GOOD', 'BAD', 'EXCELLENT', 'CAN NOT SET QUALITY']) # NOTE examples not included in propt\n",
    "    quality_reason: str = Field(..., description=\"describe reason for chosen quality_score in 1 sentece\")\n",
    "\n",
    "@outlines.prompt\n",
    "def get_metadata(text, pydantic_model):\n",
    "    \"\"\"\n",
    "    Article is delimited by (start) and (stop):\n",
    "    (start)\n",
    "    {{text}}\n",
    "    (stop)\n",
    "    Based on the article content, generate fields listed below according to their descriptions. \n",
    "    {{ pydantic_model | schema }}\n",
    "    \"\"\"\n",
    "\n",
    "prompt = get_metadata(TEXT, Metadata)\n",
    "generator = outlines.generate.json(model_mistral, Metadata)\n",
    "result = generator(prompt)\n",
    "\n",
    "result.model_dump()\n",
    "\n",
    "#---------------------------------------------------------------------------------------------\n",
    "#{'title': 'Breast cancer and protein synthesis from the perspective of bibliometric analysis', # NOTE-> not correct\n",
    "# 'authors': 'Xu, X., Yu, C., Zeng, X., Tang, W., Xu, S., Tang, L., Huang, Y., Sun, Z. and Yu, T.',  # NOTE -> first name intitials only\n",
    "# 'pub_year': 2023,\n",
    "# 'key_words': 'Breast cancer; gene expression; c-myc and bcl-xL; chart; Eastern Blot; Oncogene; Molecular Cell Biology; hypoxia; Cell Division; Cancer research', # NOTE -> strange and not 5 words\n",
    "# 'summary': \"This article presents a bibliometric analysis of research studies related to breast cancer and protein synthesis, using the Web of Science database for the period of 2003 to 2022. Over 2900 articles were retrieved containing the keywords 'breast cancer' and 'protein synthesis' in the title, abstract, and keywords. The number of publications related to breast cancer and protein synthesis has increased steadily, and the most prominent research topics include the relationship between protein expression and tumor development and treatment, the regulation of protein synthesis by hypoxia, the mechanisms and advances related to various oncogenes, c-myc, and bcl-xl, the interactions between cells and cancer cells, and the functions of various proteins in cancer-affected pathways. Notable journals associated with breast cancer and protein synthesis include the Journal of Biological Chemistry, Cancer Research, the Proceedings of the National Academy of Sciences of the United States of America, and Oncogene.\",\n",
    "# 'research_area': 'Oncology',\n",
    "# 'quality': 'good',\n",
    "# 'quality_reason': 'The article uses a well-established database and is well-written and referenced.'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dorota/LLM-diploma-project/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Metadata\n__root__\n  Unterminated string starting at: line 2 column 12 (char 13) [type=value_error.jsondecode, input_value='{\\n  \"title\": \"Visualiza...r -related protein synt', input_type=str]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/LLM-diploma-project/venv/lib/python3.10/site-packages/pydantic/main.py:1097\u001b[0m, in \u001b[0;36mBaseModel.parse_raw\u001b[0;34m(cls, b, content_type, encoding, proto, allow_pickle)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1097\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_str_bytes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m        \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproto\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontent_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/LLM-diploma-project/venv/lib/python3.10/site-packages/pydantic/deprecated/parse.py:49\u001b[0m, in \u001b[0;36mload_str_bytes\u001b[0;34m(b, content_type, encoding, proto, allow_pickle, json_loads)\u001b[0m\n\u001b[1;32m     48\u001b[0m         b \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mdecode(encoding)\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson_loads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m proto \u001b[38;5;241m==\u001b[39m Protocol\u001b[38;5;241m.\u001b[39mpickle:\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Unterminated string starting at: line 2 column 12 (char 13)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m prompt \u001b[38;5;241m=\u001b[39m get_metadata(TEXT, Metadata)\n\u001b[1;32m     29\u001b[0m generator \u001b[38;5;241m=\u001b[39m outlines\u001b[38;5;241m.\u001b[39mgenerate\u001b[38;5;241m.\u001b[39mjson(model, Metadata)\n\u001b[0;32m---> 30\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m result\u001b[38;5;241m.\u001b[39mmodel_dump()\n",
      "File \u001b[0;32m~/LLM-diploma-project/venv/lib/python3.10/site-packages/outlines/generate/api.py:501\u001b[0m, in \u001b[0;36mSequenceGeneratorAdapter.__call__\u001b[0;34m(self, prompts, max_tokens, stop_at, seed, **model_specific_params)\u001b[0m\n\u001b[1;32m    489\u001b[0m generation_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_generation_parameters(\n\u001b[1;32m    490\u001b[0m     max_tokens, stop_at, seed\n\u001b[1;32m    491\u001b[0m )\n\u001b[1;32m    493\u001b[0m completions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m    494\u001b[0m     prompts,\n\u001b[1;32m    495\u001b[0m     generation_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_specific_params,\n\u001b[1;32m    499\u001b[0m )\n\u001b[0;32m--> 501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/LLM-diploma-project/venv/lib/python3.10/site-packages/outlines/generate/api.py:487\u001b[0m, in \u001b[0;36mSequenceGeneratorAdapter.__call__.<locals>.format\u001b[0;34m(sequences)\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mformat\u001b[39m(sequence) \u001b[38;5;28;01mfor\u001b[39;00m sequence \u001b[38;5;129;01min\u001b[39;00m sequences]\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 487\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/LLM-diploma-project/venv/lib/python3.10/site-packages/outlines/generate/json.py:50\u001b[0m, in \u001b[0;36mjson.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     48\u001b[0m     regex_str \u001b[38;5;241m=\u001b[39m build_regex_from_schema(schema, whitespace_pattern)\n\u001b[1;32m     49\u001b[0m     generator \u001b[38;5;241m=\u001b[39m regex(model, regex_str, sampler)\n\u001b[0;32m---> 50\u001b[0m     generator\u001b[38;5;241m.\u001b[39mformat_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mschema_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(schema_object):\n\u001b[1;32m     52\u001b[0m     schema \u001b[38;5;241m=\u001b[39m pyjson\u001b[38;5;241m.\u001b[39mdumps(get_schema_from_signature(schema_object))\n",
      "File \u001b[0;32m~/LLM-diploma-project/venv/lib/python3.10/site-packages/pydantic/main.py:1124\u001b[0m, in \u001b[0;36mBaseModel.parse_raw\u001b[0;34m(cls, b, content_type, encoding, proto, allow_pickle)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     \u001b[38;5;66;03m# ctx is missing here, but since we've added `input` to the error, we're not pretending it's the same\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m     error: pydantic_core\u001b[38;5;241m.\u001b[39mInitErrorDetails \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1119\u001b[0m         \u001b[38;5;66;03m# The type: ignore on the next line is to ignore the requirement of LiteralString\u001b[39;00m\n\u001b[1;32m   1120\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m: pydantic_core\u001b[38;5;241m.\u001b[39mPydanticCustomError(type_str, \u001b[38;5;28mstr\u001b[39m(exc)),  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloc\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__root__\u001b[39m\u001b[38;5;124m'\u001b[39m,),\n\u001b[1;32m   1122\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m: b,\n\u001b[1;32m   1123\u001b[0m     }\n\u001b[0;32m-> 1124\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m pydantic_core\u001b[38;5;241m.\u001b[39mValidationError\u001b[38;5;241m.\u001b[39mfrom_exception_data(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, [error])\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_validate(obj)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for Metadata\n__root__\n  Unterminated string starting at: line 2 column 12 (char 13) [type=value_error.jsondecode, input_value='{\\n  \"title\": \"Visualiza...r -related protein synt', input_type=str]"
     ]
    }
   ],
   "source": [
    "# https://outlines-dev.github.io/outlines/reference/prompting/\n",
    "\n",
    "import outlines\n",
    "import outlines.generate\n",
    "import outlines.generate.json\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class Metadata(BaseModel):\n",
    "    title: str = Field(..., description=\"extract title from article\")\n",
    "    authors: str = Field(..., description=\"extract authors from article\")\n",
    "    pub_year: int = Field(..., description=\"extract publication year\")\n",
    "    key_words: str = Field(..., description=\"generate 5 new key words based on content in Abstract\")\n",
    "    summary: str = Field(..., description=\"generate summary in 3 sentences\")\n",
    "    research_area: str = Field(..., description=\"generate 1 main research area described in article\")\n",
    "    quality: str = Field(..., description=\"select one value from examples to define quality of article\", examples=['GOOD', 'BAD', 'EXCELLENT', 'CAN NOT SET QUALITY'])\n",
    "    quality_reason: str = Field(..., description=\"describe reason for chosen quality_score in 1 sentece\")\n",
    "\n",
    "@outlines.prompt\n",
    "def get_metadata(text, pydantic_model):\n",
    "    \"\"\"\n",
    "    Article is delimited by (start) and (stop):\n",
    "    (start)\n",
    "    {{text}}\n",
    "    (stop)\n",
    "    Based on the article content, generate fields listed below according to their descriptions. \n",
    "    {{ pydantic_model | schema }}\n",
    "    \"\"\"\n",
    "\n",
    "prompt = get_metadata(TEXT, Metadata)\n",
    "generator = outlines.generate.json(model, Metadata)\n",
    "result = generator(prompt)\n",
    "\n",
    "result.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Metadata.model_fields['quality'].examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = generate.choice(model, [\"skirt\", \"dress\", \"pen\", \"jacket\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
